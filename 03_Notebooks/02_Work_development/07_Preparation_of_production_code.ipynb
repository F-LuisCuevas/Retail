{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bb2255",
   "metadata": {},
   "source": [
    "##  FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e8fca",
   "metadata": {},
   "source": [
    "### DATA QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98177b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality(x):\n",
    "    \n",
    "    #types\n",
    "    temp = x.astype({'month': 'O', 'wday': 'O'})             \n",
    "    \n",
    "    #Impute nulls\n",
    "    temp.loc[x['event_name_1'].isna(),'event_name_1'] = 'no_event'\n",
    "    \n",
    "    def impute_mode(records):\n",
    "        #mode of price in that product\n",
    "        mode = records.sell_price.mode()[0]\n",
    "        #Impute nulls\n",
    "        records.loc[records.sell_price.isna(),'sell_price'] = mode\n",
    "    \n",
    "        return(records)\n",
    "\n",
    "    temp = temp.groupby('item_id').apply(impute_mode)\n",
    "      \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e57147",
   "metadata": {},
   "source": [
    "### Creation of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a57bd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variables(x):\n",
    "    \n",
    "    # INTERMITTENT DEMAND\n",
    "    \n",
    "    def stock_break(sales, n = 5):\n",
    "        zero_sales = pd.Series(np.where(sales == 0,1,0))\n",
    "        num_zeros = zero_sales.rolling(n).sum()\n",
    "        stock_break = np.where(num_zeros == n,1,0)\n",
    "        return(stock_break)\n",
    "    \n",
    "    x = x.sort_values(by = ['store_id','item_id','date'])\n",
    "    x['stock_break_3'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x, 3)).values\n",
    "    x['stock_break_7'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x,7)).values\n",
    "    x['stock_break_15'] = x.groupby(['store_id','item_id']).sales.transform(lambda x: stock_break(x,15)).values\n",
    "    \n",
    "    \n",
    "    #LAGS\n",
    "    \n",
    "    def make_lags(x, variable, num_lags = 7):\n",
    "        lags = pd.DataFrame()\n",
    "        for cada in range(1,num_lags+1):\n",
    "            lags[variable + '_lag_'+ str(cada)] = x[variable].shift(cada)\n",
    "        return(lags)\n",
    "    \n",
    "    lags_sell_price_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: make_lags(x = x, variable = 'sell_price', num_lags= 7))\n",
    "    \n",
    "    lags_stock_break_3_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: make_lags(x = x, variable = 'stock_break_3', num_lags= 1))\n",
    "    \n",
    "    lags_stock_break_7_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: make_lags(x = x, variable = 'stock_break_7', num_lags= 1))\n",
    "    \n",
    "    lags_stock_break_15_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: make_lags(x = x, variable = 'stock_break_15', num_lags= 1))\n",
    "    \n",
    "    lags_sales_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: make_lags(x = x, variable = 'sales', num_lags= 15))\n",
    "    \n",
    "    \n",
    "    # MOBILE WINDOWS\n",
    "    \n",
    "    def min_movil(x, variable, num_periods = 7):\n",
    "        minm = pd.DataFrame()\n",
    "        for cada in range(2,num_periods+1):\n",
    "            minm[variable + '_minm_' + str(cada)] = x[variable].shift(1).rolling(cada).min()\n",
    "        return(minm)\n",
    "    \n",
    "    def mean_movil(x, variable, num_periods = 7):\n",
    "        mm = pd.DataFrame()\n",
    "        for cada in range(2,num_periods+1):\n",
    "            mm[variable + '_mm_' + str(cada)] = x[variable].shift(1).rolling(cada).mean()\n",
    "        return(mm)\n",
    "    \n",
    "    def max_movil(x, variable, num_periods = 7):\n",
    "        maxm = pd.DataFrame()\n",
    "        for cada in range(2,num_periods+1):\n",
    "            maxm[variable + '_maxm_' + str(cada)] = x[variable].shift(1).rolling(cada).max()\n",
    "        return(maxm)\n",
    "    \n",
    "    min_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: min_movil(x = x, variable = 'sales', num_periods= 15))\n",
    "    \n",
    "    mean_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: mean_movil(x = x, variable = 'sales', num_periods= 15))\n",
    "    \n",
    "    max_movil_x = x.groupby(['store_id','item_id'])\\\n",
    "                    .apply(lambda x: max_movil(x = x, variable = 'sales', num_periods= 15))\n",
    "    \n",
    "    \n",
    "    #JOIN GENERATED DATAFRAMES\n",
    "    \n",
    "    x_join = pd.concat([x,\n",
    "                      lags_sell_price_x,\n",
    "                      lags_stock_break_3_x,\n",
    "                      lags_stock_break_7_x,\n",
    "                      lags_stock_break_15_x,\n",
    "                      lags_sales_x,\n",
    "                      min_movil_x,\n",
    "                      mean_movil_x,\n",
    "                      max_movil_x], axis = 1)\n",
    "\n",
    "    x_join.dropna(inplace=True)\n",
    "    \n",
    "    x_join.drop(columns = ['sell_price','stock_break_3','stock_break_7','stock_break_15'],\n",
    "                  inplace=True)\n",
    "    \n",
    "    #Create a single variable for the product\n",
    "    x_join.insert(loc=0,column='producto',value=x_join.store_id + '_'+ x_join.item_id)\n",
    "    x_join = x_join.drop(columns = ['store_id','item_id'])\n",
    "    \n",
    "    return(x_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa892d",
   "metadata": {},
   "source": [
    "###  Variable transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee711664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_variables(x,y=None,mode = 'training'):\n",
    "    \n",
    "    '''\n",
    "    I have modified this function so that it works for both training and execution:\n",
    "\n",
    "    * Including the mode parameter, which defaults to training\n",
    "    * Making the y parameter optional, since in execution it is not used\n",
    "\n",
    "    When used in training mode apply the fit_transform method and save the objects.\n",
    "\n",
    "    While when used in run mode it loads the objects and applies only the transform method.\n",
    "    '''\n",
    "    \n",
    "    x.reset_index(inplace = True)\n",
    "\n",
    "    #ENCODERS\n",
    "    name_ohe = 'ohe_retail.pickle'\n",
    "    name_te = 'te_retail.pickle'\n",
    "    path_ohe = path + '/04_Models/' + name_ohe\n",
    "    path_te = path + '/04_Models/' + name_te\n",
    "    \n",
    "    #ONE HOT ENCODING\n",
    "    var_ohe = ['event_name_1']\n",
    "    if mode == 'training':\n",
    "        #If it is in training apply fit_transform and save the encoder\n",
    "        ohe = OneHotEncoder(sparse = False, handle_unknown='ignore')\n",
    "        ohe_x = ohe.fit_transform(x[var_ohe])\n",
    "        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n",
    "        with open(path_ohe, mode='wb') as file:\n",
    "           pickle.dump(ohe, file)\n",
    "    else:\n",
    "        # If it is running it retrieves the save and just applies transform\n",
    "        with open(path_ohe, mode='rb') as file:\n",
    "            ohe = pickle.load(file)\n",
    "        ohe_x = ohe.transform(x[var_ohe])\n",
    "        ohe_x = pd.DataFrame(ohe_x, columns = ohe.get_feature_names_out())\n",
    "\n",
    "    #TARGET ENCODING    \n",
    "    var_te = ['month','wday','weekday']\n",
    "    if mode == 'training':\n",
    "        # MAKE SURE Y HAS THE SAME REGISTERS AS X\n",
    "        y.reset_index(inplace = True, drop = True)\n",
    "        y = y.loc[y.index.isin(x.index)]\n",
    "        # If it is in training apply fit_transform and save the encoder\n",
    "        te = TargetEncoder(min_samples_leaf=100, return_df = False)\n",
    "        te_x = te.fit_transform(x[var_te], y = y)\n",
    "        names_te = [variable + '_te' for variable in var_te]\n",
    "        te_x = pd.DataFrame(te_x, columns = names_te)\n",
    "        with open(path_te, mode='wb') as file:\n",
    "           pickle.dump(te, file)\n",
    "    else:\n",
    "        # If it is running it retrieves the save and just applies transform\n",
    "        with open(path_te, mode='rb') as file:\n",
    "            te = pickle.load(file)\n",
    "        te_x = te.transform(x[var_te])\n",
    "        names_te = [variable + '_te' for variable in var_te]\n",
    "        te_x = pd.DataFrame(te_x, columns = names_te)\n",
    "    \n",
    "      \n",
    "\n",
    "    #INTEGRATE, CLEAN AND RETURN THE DATAFRAME\n",
    "    #Delete the already transformed originals\n",
    "    x = x.drop(columns=['event_name_1','month','wday','weekday'])\n",
    "\n",
    "    x = pd.concat([x,ohe_x,te_x], axis=1).set_index('date')\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27238586",
   "metadata": {},
   "source": [
    "### Variables Pre-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88ebaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_selection(x,y):\n",
    "    \n",
    "    '''\n",
    "    only for fit.\n",
    "    '''\n",
    "    #DROP COLUMN PRODUCTO AND THE INDEX\n",
    "    x.reset_index(drop = True,inplace = True)\n",
    "    x.drop(columns='producto',inplace = True)\n",
    "    \n",
    "    # verify x and y need to have same size\n",
    "    y = y.loc[y.index.isin(x.index)]\n",
    "    \n",
    "\n",
    "    mutual_selector = mutual_info_regression(x,y)\n",
    "    position_variable_limit = 70\n",
    "    ranking_mi = pd.DataFrame(mutual_selector, index = x.columns).reset_index()\n",
    "    ranking_mi.columns = ['variable','importance_mi']\n",
    "    ranking_mi = ranking_mi.sort_values(by = 'importance_mi', ascending = False)\n",
    "    ranking_mi['ranking_mi'] = np.arange(0,ranking_mi.shape[0])\n",
    "    in_mi = ranking_mi.iloc[0:position_variable_limit].variable\n",
    "    x_mi = x[in_mi].copy()\n",
    "\n",
    "    return(x_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3f141",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa223b8",
   "metadata": {},
   "source": [
    "#### FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81e214da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(x_producto, y):\n",
    "    \n",
    "    '''\n",
    "    This function is what does the individual modeling.\n",
    "\n",
    "    Receives the x and y data of a product.\n",
    "\n",
    "    Find the optimal parameters for that product.\n",
    "\n",
    "    Returns the best model.\n",
    "    '''\n",
    "      \n",
    "    \n",
    "    #Exclude product as a modeling variable\n",
    "    var_model = x_producto.columns.to_list()[2:]\n",
    "    \n",
    "    #Define cross validation\n",
    "    time_cv = TimeSeriesSplit(5, test_size = 8)\n",
    "    \n",
    "    #Define algorithm grid\n",
    "    pipe = Pipeline([('algorithm',HistGradientBoostingRegressor())])\n",
    "    \n",
    "    grid = [ \n",
    "         {'algorithm': [HistGradientBoostingRegressor()]\n",
    "#          'algoritmo__learning_rate': [0.01,0.025,0.05,0.1],\n",
    "#          'algoritmo__max_iter': [50,100,200],\n",
    "#          'algoritmo__max_depth': [5,10,20,50],\n",
    "#          'algoritmo__scoring': ['neg_mean_absolute_error'],\n",
    "#          'algoritmo__l2_regularization': [0,0.25,0.5,0.75,1]\n",
    "         }\n",
    "                       \n",
    "    ]\n",
    "           \n",
    "    #make models\n",
    "    random_search = RandomizedSearchCV(estimator = pipe,\n",
    "                                   param_distributions = grid, \n",
    "                                   n_iter = 1, \n",
    "                                   cv = time_cv, \n",
    "                                   scoring = 'neg_mean_absolute_error', \n",
    "                                   verbose = 0,\n",
    "                                   n_jobs = -1)\n",
    "    \n",
    "    model = random_search.fit(x_producto[var_model],y)\n",
    "    \n",
    "    #Retrain the best over all datas\n",
    "    final_model = model.best_estimator_.fit(x_producto[var_model],y)\n",
    "\n",
    "    return(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33a52d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df):\n",
    "    \n",
    "    '''\n",
    "    This function goes through all the products and calls modelling() to create a total list with all the models of all the products.\n",
    "\n",
    "    It receives the dataframe of the x's already cleaned and segmented by product, and also the target.\n",
    "\n",
    "    It does not return anything, but saves the object already trained with all the models on disk.\n",
    "    '''\n",
    "    \n",
    "    list_products = list(df.producto.unique())\n",
    "    \n",
    "    list_models =[] \n",
    "    \n",
    "    for cada in list_products:\n",
    "        \n",
    "        #Rename\n",
    "        producto = cada\n",
    "        target = 'sales'\n",
    "\n",
    "        x = df.loc[df.producto == producto].copy().drop(columns=target).copy()\n",
    "        y = df.loc[df.producto == producto,'sales'].copy()\n",
    "\n",
    "        x = transform_variables(x,y)\n",
    "        x = variables_selection(x,y)\n",
    "        \n",
    "        #call a la function de modelling\n",
    "        model = modelling(x,y)\n",
    "        \n",
    "        #Add final model to the list\n",
    "        list_models.append((producto,model))\n",
    "        \n",
    "    #save list of fit models\n",
    "    name_models = 'list_models_retail.pickle'\n",
    "    path_models = path + '/04_Models/' + name_models\n",
    "    with open(path_models, mode='wb') as file:\n",
    "       pickle.dump(list_models, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4270ad",
   "metadata": {},
   "source": [
    "#### EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bb32084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run prediction\n",
    "def run_execution(df):\n",
    "    \n",
    "    '''\n",
    "    This function makes the forecast for each product, but only for one day.\n",
    "\n",
    "    Receives the new dataset to predict.\n",
    "    \n",
    "    It must have the structure of the file DatosParaProduccion.csv in the Validation folder.\n",
    "\n",
    "    It goes through each product, loading its corresponding model, selecting its data, and making predictions.\n",
    "\n",
    "    Returns the prediction for all the products but ONLY FOR THE DAY THAT IS TOUCHED.\n",
    "    '''\n",
    "    \n",
    "    #upload models\n",
    "    name_models = 'list_models_retail.pickle'\n",
    "    path_models = path + '/04_Models/' + name_models\n",
    "    with open(path_models, mode='rb') as file:\n",
    "       list_models = pickle.load(file)\n",
    "    \n",
    "    predictions_df = pd.DataFrame(columns=['date','producto','sales','predictions'])\n",
    "    \n",
    "    for cada in range(0,len(list_models)):\n",
    "\n",
    "        producto = list_models[cada][0]\n",
    "        model = list_models[cada][1]\n",
    "        variables = model[0].feature_names_in_\n",
    "        target = 'sales'\n",
    "        \n",
    "        x = df.loc[df.producto == producto].copy().drop(columns=target).copy()\n",
    "        y = df.loc[df.producto == producto,'sales'].copy()\n",
    "        \n",
    "        date = df.reset_index().copy()\n",
    "        date = date.loc[date.producto == producto,'date'].values\n",
    "\n",
    "        #Transformation of variables\n",
    "        x = transform_variables(x, mode = 'execution')\n",
    "        \n",
    "        #Variables Selection\n",
    "        x = x[variables]\n",
    "        \n",
    "        #Predictions\n",
    "        predictions = pd.DataFrame(data={'date': date,\n",
    "                                          'producto': producto,\n",
    "                                          'sales': y,\n",
    "                                          'prediction': model.predict(x)})\n",
    "\n",
    "        predictions['prediction'] = predictions.prediction.astype('int')\n",
    "\n",
    "        predictions_df = pd.concat([predictions_df,predictions])\n",
    "    \n",
    "    predictions_df = predictions_df.loc[predictions_df.index == predictions_df.index.min()]\n",
    "    return(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c4a5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_recursive(x):\n",
    "    '''\n",
    "    This function is the one that applies the recursive forecast to predict 8 days.\n",
    "    \n",
    "    Receives the new dataset to predict.\n",
    "\n",
    "    It must have the structure of the file DatosParaProduccion.csv in the Validation folder.\n",
    "    \n",
    "    Since to apply recursion:\n",
    "\n",
    "    * It will predict the first day for which it has all the information (ie 15 days from the oldest day)\n",
    "    * When finished, it saves the sales prediction in the record to be predicted and eliminates the records of the oldest day in the data frame.\n",
    "    * Therefore in the next iteration it will predict the next day.\n",
    "\n",
    "    For example:\n",
    "\n",
    "    If the oldest day in the dataset is 12/09/2015 then the first day you can predict\n",
    "    \n",
    "    (and of which we no longer have data) is 12/24/2015.\n",
    "\n",
    "    When you predict the data of 24 for each product you overwrite it as your sales\n",
    "    \n",
    "    and removes all records from day 09.\n",
    "\n",
    "    Then the oldest day becomes the 10th and therefore the day to predict is the 25th.\n",
    "\n",
    "    And so until the end of 8 cycles to predict the week we want.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    for cada in range(0,8):\n",
    "        step1_df = data_quality(x)\n",
    "        step2_df = make_variables(step1_df)\n",
    "        \n",
    "        #predict\n",
    "        f = run_execution(step2_df)\n",
    "        f['store_id'] = f.producto.str[:4]\n",
    "        f['item_id'] = f.producto.str[5:]\n",
    "\n",
    "        #Update sales data with prediction\n",
    "        x.loc[(x.index.isin(f.date)) & (x.store_id.isin(f.store_id)) & (x.item_id.isin(f.item_id)),'sales'] = f.prediction\n",
    "                                                              \n",
    "        #Drop last day of x\n",
    "        x = x.loc[x.index != x.index.min()]\n",
    "        \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e988cc2",
   "metadata": {},
   "source": [
    "## PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a26aa7",
   "metadata": {},
   "source": [
    "### RETRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39e901fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#upload data\n",
    "path = '../../'\n",
    "name_data_file = 'work.csv'\n",
    "full_path = path + '/02_Data/03_Work/'+ name_data_file\n",
    "df = pd.read_csv(full_path,sep=',',parse_dates=['date'],index_col='date')\n",
    "\n",
    "#Select variables used\n",
    "final_variables = ['store_id',\n",
    "                     'item_id',\n",
    "                     'event_name_1',                     \n",
    "                     'month',\n",
    "                     'sell_price',                      \n",
    "                     'wday',\n",
    "                     'weekday',\n",
    "                     'sales']\n",
    "\n",
    "df = df[final_variables]\n",
    "\n",
    "step1_df = data_quality(df)\n",
    "step2_df = make_variables(step1_df)\n",
    "\n",
    "run_training(step2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edca8c",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f22b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  5.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>producto</th>\n",
       "      <th>sales</th>\n",
       "      <th>predictions</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_090</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_120</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_202</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_252</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_288</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_329</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_555</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_586</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_587</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_3_FOODS_3_714</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_090</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_120</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_202</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_252</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_288</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_329</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_555</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_586</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_587</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-16</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>CA_4_FOODS_3_714</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date          producto sales predictions  prediction\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_090     0         NaN       -10.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_120    52         NaN        51.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_202    20         NaN        17.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_252    36         NaN        35.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_288    35         NaN        23.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_329    64         NaN        43.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_555    30         NaN        26.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_586    76         NaN        63.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_587    29         NaN        33.0\n",
       "2015-12-16 2015-12-16  CA_3_FOODS_3_714    19         NaN        17.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_090     0         NaN        -1.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_120    16         NaN         3.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_202    11         NaN        14.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_252     5         NaN         6.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_288     3         NaN         6.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_329    10         NaN         6.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_555     4         NaN         3.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_586    10         NaN        11.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_587     5         NaN         9.0\n",
       "2015-12-16 2015-12-16  CA_4_FOODS_3_714    11         NaN         9.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Upload data\n",
    "path = '../../'\n",
    "name_data_file = 'validation.csv'\n",
    "full_path = path + '/02_Data/02_Validation/' + name_data_file\n",
    "df = pd.read_csv(full_path,sep=',',parse_dates=['date'],index_col='date')\n",
    "\n",
    "#Select only used\n",
    "final_variables = ['store_id',\n",
    "                     'item_id',\n",
    "                     'event_name_1',                     \n",
    "                     'month',\n",
    "                     'sell_price',                      \n",
    "                     'wday',\n",
    "                     'weekday',\n",
    "                     'sales']\n",
    "\n",
    "\n",
    "df = df[final_variables]\n",
    "\n",
    "step1_df = data_quality(df)\n",
    "step2_df = make_variables(step1_df)\n",
    "\n",
    "forecast_1day = run_execution(step2_df)\n",
    "\n",
    "print('MAE = ', mean_absolute_error(forecast_1day.sales,forecast_1day.prediction))\n",
    "\n",
    "forecast_1day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535e505",
   "metadata": {},
   "source": [
    "### EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13384465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>month</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>wday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-12-17</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-18</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-19</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-20</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-21</th>\n",
       "      <td>CA_3</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-27</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-28</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>CA_4</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1.58</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           store_id      item_id event_name_1  month  sell_price  wday  \\\n",
       "date                                                                     \n",
       "2015-12-17     CA_3  FOODS_3_090          NaN     12        1.00     6   \n",
       "2015-12-18     CA_3  FOODS_3_090          NaN     12        1.00     7   \n",
       "2015-12-19     CA_3  FOODS_3_090          NaN     12        1.00     1   \n",
       "2015-12-20     CA_3  FOODS_3_090          NaN     12        1.00     2   \n",
       "2015-12-21     CA_3  FOODS_3_090          NaN     12        1.00     3   \n",
       "...             ...          ...          ...    ...         ...   ...   \n",
       "2015-12-27     CA_4  FOODS_3_714          NaN     12        1.58     2   \n",
       "2015-12-28     CA_4  FOODS_3_714          NaN     12        1.58     3   \n",
       "2015-12-29     CA_4  FOODS_3_714          NaN     12        1.58     4   \n",
       "2015-12-30     CA_4  FOODS_3_714          NaN     12        1.58     5   \n",
       "2015-12-31     CA_4  FOODS_3_714          NaN     12        1.58     6   \n",
       "\n",
       "              weekday  sales  \n",
       "date                          \n",
       "2015-12-17   Thursday      0  \n",
       "2015-12-18     Friday      1  \n",
       "2015-12-19   Saturday      0  \n",
       "2015-12-20     Sunday      6  \n",
       "2015-12-21     Monday      4  \n",
       "...               ...    ...  \n",
       "2015-12-27     Sunday      7  \n",
       "2015-12-28     Monday      9  \n",
       "2015-12-29    Tuesday      7  \n",
       "2015-12-30  Wednesday      8  \n",
       "2015-12-31   Thursday      9  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Upload data\n",
    "path = '../../'\n",
    "name_data_file = 'DataForProduction.csv'\n",
    "full_path = path + '/02_Data/02_Validation/' + name_data_file\n",
    "df = pd.read_csv(full_path,sep=';',parse_dates=['date'],index_col='date')\n",
    "\n",
    "#Seleccionar solo las que se han usado\n",
    "final_variables = ['store_id',\n",
    "                     'item_id',\n",
    "                     'event_name_1',                     \n",
    "                     'month',\n",
    "                     'sell_price',                      \n",
    "                     'wday',\n",
    "                     'weekday',\n",
    "                     'sales']\n",
    "\n",
    "df = df[final_variables]\n",
    "\n",
    "#run predictions\n",
    "forecast = forecast_recursive(df)\n",
    "\n",
    "forecast.sort_values(by = ['store_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e7cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fbb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
